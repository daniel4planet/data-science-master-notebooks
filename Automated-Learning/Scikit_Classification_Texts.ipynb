{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso Práctico 4.4:  Clasificación de textos con Scikit-Learn\n",
    "\n",
    "* En este notebook vamos a ver como clasificar una serie de Tweets en Ingles sobre críticas a los productos de Apple.\n",
    "\n",
    "\n",
    "* Estos tweets estan clasificados como: *positivos*, *neutros* o *negativos*\n",
    "\n",
    "\n",
    "* El este notebook realizaremos los siguientes pasos:\n",
    "    \n",
    "    1. Carga de los datos (tweets)\n",
    "    2. Normalización (en ingles) de los tweets\n",
    "    3. Creación de la Bolsa de Palabras\n",
    "    4. Particionado de Datos\n",
    "    5. Creación de modelos\n",
    "        - Multinomial Naive Bayes\n",
    "        - Bernoulli Naive Bayes\n",
    "        - Regresion Logistica\n",
    "        - Support Vector Machine\n",
    "        - Random Forest <sup>(*)Meta-Modelo</sup>\n",
    "    6. Evaluación de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Carga de Datos\n",
    "\n",
    "\n",
    "* El primer paso que vamos a realizar es el de cargar los datos. Para ello ***leeremos el csv con pandas*** (pasandolo a un dataframe) y posteriormente lo transformaremos en una lista de tuplas (*tweets*) donde cada tupla esta formada por:\n",
    "    - **Posición 0**: Tweet\n",
    "    - **Posición 1**: Polaridad (Positivo | Neutro | Negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de Tweets Cargados: 3804\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tweets_file = './data/Apple_Tweets.csv'\n",
    "df = pd.read_csv(tweets_file, header=None)\n",
    "tweets = [tuple(x) for x in df.values]\n",
    "print('Número de Tweets Cargados: {num}'.format(num=len(tweets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Normalización\n",
    "\n",
    "* Para este ejemplo haremos uso de ***spaCy***, pero en este caso tenemos que utilizar (e importar) el modelo para Inglés. Para ello: debemos de abrir un terminal en python y ejecutar lo siguiente para descargar el modelo en Ingles (*NOTA: los que uséis conda, tener activado el entorno*).\n",
    "\n",
    "\n",
    "```\n",
    ">> python3 -m spacy download en_core_web_sm\n",
    "```\n",
    "\n",
    "\n",
    "<img src=\"./imgs/010_spacy_en_download.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "* Para ***normalizar*** los tweets realizaremos las siguientes acciones:\n",
    "    1. Pasamos las frases a minúsculas.\n",
    "    2. Eliminamos los signos de puntuación.\n",
    "    3. Eliminamos las palabras con menos de 3 caracteres.\n",
    "    4. Eliminamos las Stop-Words.\n",
    "    5. Eliminamos las palabras que empiecen por '@' o 'http'.\n",
    "    6. Pasamos la palabra a su lema\n",
    "\n",
    "\n",
    "* Todos estos pasos los vamos a realizar en una misma función.\n",
    "\n",
    "\n",
    "* ***NOTA***: *De cara a la normalización de textos se pueden realizar más acciones que las que vamos a realizar, pero con estas serán más que suficientes para realizar un ejercicio con fines didácticos*\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Divido los datos en dos listas \n",
    "#     X: los tweets\n",
    "#     y: target (polaridad)\n",
    "\n",
    "X = [doc[0] for doc in tweets]\n",
    "y = [doc[1] for doc in tweets]\n",
    "\n",
    "def normalize(sentenses):\n",
    "    \"\"\"normalizamos la lista de frases y devolvemos la misma lista de frases normalizada\"\"\"\n",
    "    for index, sentense in enumerate(sentenses):\n",
    "        sentense = nlp(sentense.lower()) # Paso la frase a minúsculas y a un objeto de la clase Doc de Spacy\n",
    "        sentenses[index] = \" \".join([word.lemma_ for word in sentense if (not word.is_punct)\n",
    "                                     and (len(word.text) > 2) and (not word.is_stop) \n",
    "                                     and (not word.text.startswith('@')) and (not word.text.startswith('http'))])\n",
    "    return sentenses\n",
    "\n",
    "# Normalizamos las frases\n",
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Bolsa de Palabras\n",
    "\n",
    "\n",
    "* El siguiente paso es transformar los tweets a una bolsa de palabras de frecuencias para que sirva de entrada al modelo.\n",
    "\n",
    "\n",
    "* Dado que ya estamos trabajando con un corpus relativamente grande, es necesario reducir el diccionario de palabras (no confundir con un diccionario Python) para trabajar solo con las palabras más relevantes.\n",
    "\n",
    "\n",
    "* La implementación de la clase \"*CountVectorizer*\" de scikit, permite quedarnos con las palabras más relevante. Para ello podemos utilizar dos parámetros que son:\n",
    "    - **max_features**: Con este parámetro le indicamos que nos seleccione la '*X*' palabras más frecuentes del corpus. En este ejemplo **seleccionaremos las 1000 más frecuentes**.\n",
    "    - **min_df**: Con este parámetro le indicamos el número mínimo de documentos en la que tiene que aparecer la palabra para que se incluya en la bolsa de palabras. En este ejemplo **seleccionaremos 3 documentos** (tweets).\n",
    "    \n",
    "\n",
    "* ***NOTA***: para más información podéis mirar la documentación de la clase \"*CountVectorizer*\" en: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1000, min_df=3)\n",
    "\n",
    "# Pasamos los tweets normalizados a Bolsa de palabras\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Particionado de Datos (Train y Test)\n",
    "\n",
    "* Vamos a particionar los datos en conjunto de Train y Test.\n",
    "\n",
    "\n",
    "* Para este ejemplo nos vamos a quedar con:\n",
    "    - 80% de datos de entrenamiento\n",
    "    - 20% de datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print('Número de Tweets para el entrenamiento: {num}'.format(num=X_train.shape[0]))\n",
    "print('Número de Tweets para el test: {num}'.format(num=X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Creacción del Modelo\n",
    "\n",
    "\n",
    "* Una vez tenemos creada la bolsa de palabras, podemos usar cualquier algoritmo de aprendizaje para la clasificación.\n",
    "\n",
    "\n",
    "* Para este ejemplo vamos a usar los siguientes algoritmos de aprendizaje:\n",
    "\n",
    "    - Multinomial Naive Bayes: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "    - Bernoulli Naive Bayes: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html\n",
    "    - Regresion Logistica: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "    - Support Vector Machine Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "    - Random Forest (ensemble): https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "    \n",
    "\n",
    "* Para esta caso vamos a crear el modelo y calcular el accuracy para los datos de entrenamiento y tener una idea de que modelo puede funciona mejor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()\n",
    "lr = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "svm_lin = SVC(kernel='linear')\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "rf_50 = RandomForestClassifier(n_estimators=500, bootstrap=True, criterion='gini', max_depth=50, random_state=0)\n",
    "\n",
    "clasificadores = {'Multinomial NB': mnb,\n",
    "                  'Bernoulli NB': bnb,\n",
    "                  'Regresion Logistica': lr,\n",
    "                  'SVM lineal': svm_lin,\n",
    "                  'SVM Kernel rbf': svm_rbf,\n",
    "                  'Random Forest d_50': rf_50}\n",
    "\n",
    "\n",
    "# Ajustamos los modelos y calculamos el accuracy para los datos de entrenamiento\n",
    "for k, v in clasificadores.items():\n",
    "    print ('CREANDO MODELO: {clas}'.format(clas=k))\n",
    "    v.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Evaluación del Modelo\n",
    "\n",
    "\n",
    "* Para cada uno de los modelos vamos a calcular las siguientes métricas de evaluación:\n",
    "\n",
    "    1. **Accuracy**\n",
    "    2. **Precision**\n",
    "    3. **Recall**\n",
    "    4. **F1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluation(model, name, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Función de devuelve en un diccionario las métricas de evaluación de \n",
    "    Accuracy, Precision, Recall y F1 para los conjuntos de datos de entrenamiento y test\n",
    "        model: modelo a evaluar\n",
    "        name: nombre del modelo\n",
    "        X_train: Variables de entrada del conjunto de datos de entrenamiento\n",
    "        y_train: Variable de salida del conjunto de datos de entrenamiento\n",
    "        X_test: Variables de entrada del conjunto de datos de test\n",
    "        y_test: Variable de salida del conjunto de datos de test\n",
    "        return: diccionario con el nombre del modelo y el valor de las métricas\n",
    "    \"\"\"\n",
    "    model_dict = {}\n",
    "    model_dict['name'] = name\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    model_dict['accuracy_train'] = accuracy_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    model_dict['accuracy_tests'] = accuracy_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    model_dict['precision_train'] = precision_score(y_true=y_train, y_pred=y_pred_train, average='weighted')\n",
    "    model_dict['precision_tests'] = precision_score(y_true=y_test, y_pred=y_pred_test, average='weighted')\n",
    "    model_dict['recall_train'] = recall_score(y_true=y_train, y_pred=y_pred_train, average='weighted')\n",
    "    model_dict['recall_tests'] = recall_score(y_true=y_test, y_pred=y_pred_test, average='weighted')\n",
    "    model_dict['f1_train'] = f1_score(y_true=y_train, y_pred=y_pred_train, average='weighted')\n",
    "    model_dict['f1_tests'] = f1_score(y_true=y_test, y_pred=y_pred_test, average='weighted')\n",
    "    \n",
    "    return model_dict\n",
    "\n",
    "\n",
    "# Calculamos las métricas de los modelos por separado\n",
    "evaluacion = list()\n",
    "for key, model in clasificadores.items():\n",
    "    evaluacion.append(evaluation(model=model, name=key, \n",
    "                                 X_train=X_train, y_train=y_train,\n",
    "                                 X_test=X_test, y_test=y_test))\n",
    "\n",
    "# Pasamos los resultados a un DataFrame para visualizarlos mejor\n",
    "df = pd.DataFrame.from_dict(evaluacion)\n",
    "df.set_index(\"name\", inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Representamos las métricas para los diferentes modelos en un gráfico de barras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Métricas a pintar\n",
    "METRICS = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "\n",
    "# Transformamos el dataframe para pintar las gráficas con seaborn\n",
    "df_plot = df.reset_index().melt(id_vars='name').rename(columns=str.title)\n",
    "\n",
    "plt.figure(figsize=(25, 12))\n",
    "pos = 1\n",
    "for metric in METRICS:\n",
    "    # Filtramos la métrica a pintar\n",
    "    df_aux = df_plot[df_plot['Variable'].str.contains(metric)]\n",
    "    \n",
    "    # Pintamos la gráfica en su posición 2x2\n",
    "    plt.subplot(2, 2, pos)\n",
    "    sns.barplot(x='Name', y='Value', hue='Variable', data=df_aux)\n",
    "    plt.title(metric.upper())\n",
    "    plt.grid()\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "    plt.xticks(rotation=20)\n",
    "    pos += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Veamos las matrices de confusión de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Obtenemos las Matrices de confusión\n",
    "msc = list()\n",
    "for k, v in clasificadores.items():\n",
    "    print ('Obteniendo Matriz de Confusión de: {model}'.format(model=k))\n",
    "    model = {}\n",
    "    model['name'] = k\n",
    "    y_pred_train = v.predict(X_train)\n",
    "    y_pred_test = v.predict(X_test)\n",
    "    model['confusion_matrix_train'] = confusion_matrix(y_true=y_train, y_pred=y_pred_train)\n",
    "    model['confusion_matrix_test'] = confusion_matrix(y_true=y_test, y_pred=y_pred_test)\n",
    "    msc.append(model)\n",
    "\n",
    "    \n",
    "# Definimos el heatmap de la matriz de confusión\n",
    "def plot_confusion_matrix(cm, classes, title, cmap=plt.cm.Greens):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "# Pintamos las matrices de confusión\n",
    "plt.figure(figsize=(20, 45))\n",
    "pos = 0\n",
    "for mc in msc:\n",
    "    pos += 1\n",
    "    plt.subplot(6, 2, pos)\n",
    "    plot_confusion_matrix(mc['confusion_matrix_train'], classes=['positive', 'neutral', 'negative'], \n",
    "                          title='{}\\nMatriz de Confusión Datos Entrenamiento'.format(mc['name']))\n",
    "    pos += 1\n",
    "    plt.subplot(6, 2, pos)\n",
    "    plot_confusion_matrix(mc['confusion_matrix_test'], classes=['positive', 'neutral', 'negative'], \n",
    "                          title='{}\\nMatriz de Confusión Datos Tests'.format(mc['name'] ))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
